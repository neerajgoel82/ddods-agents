{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content planner flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you get started:\n",
    "\n",
    "Create a .env file in the directory and store these two values:\n",
    "\n",
    "- FIRECRAWL_API_KEY=\"fc-...\" (get the firecrawl API key here: https://www.firecrawl.dev/i/api)\n",
    "- OPENAI_API_KEY=\"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install firecrawl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import uuid\n",
    "import yaml\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "# Firecrawl SDK\n",
    "from firecrawl import FirecrawlApp\n",
    "\n",
    "# Importing Crew related components\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "# Importing CrewAI Flow related components\n",
    "from crewai.flow.flow import Flow, listen, start, router, or_\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Option D: Azure OpenAI\n",
    "openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "openai_model_name = os.getenv(\"AZURE_OPENAI_MODEL_NAME\")\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"azure/gpt-4o-mini\",\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_endpoint,\n",
    "    api_version=openai_api_version,\n",
    "    azure=True\n",
    ")\n",
    "\n",
    "print(\"ðŸš€ Environment configured!\")\n",
    "print(f\"LLM Model: {llm.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_post_url = \"https://blog.dailydoseofds.com/p/5-chunking-strategies-for-rag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter and LinkedIn Planning Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define structured output for twitter and linkedin\n",
    "\n",
    "class Tweet(BaseModel):\n",
    "    \"\"\"Represents an individual tweet in a thread\"\"\"\n",
    "    content: str\n",
    "    is_hook: bool = False  # Identifies if this is the opening/hook tweet\n",
    "    media_urls: Optional[list[str]] = []  # Optional media attachments (images, code snippets)\n",
    "\n",
    "class Thread(BaseModel):\n",
    "    \"\"\"Represents a Twitter thread\"\"\"\n",
    "    topic: str  # Main topic/subject of the thread\n",
    "    tweets: list[Tweet]  # List of tweets in the thread\n",
    "\n",
    "class LinkedInPost(BaseModel):\n",
    "    \"\"\"Represents a LinkedIn post\"\"\"\n",
    "    content: str\n",
    "    media_url: str # Main image url for the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load agent and task configurations from yaml files and tools\n",
    "\n",
    "from crewai_tools import (\n",
    "    DirectoryReadTool,\n",
    "    FileReadTool,\n",
    ")\n",
    "\n",
    "# Load agent and task configurations from YAML files\n",
    "with open('config/planner_agents.yaml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('config/planner_tasks.yaml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agents, their tasks and crew for twitter\n",
    "\n",
    "draft_analyzer = Agent(config=agents_config['draft_analyzer'], tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool()\n",
    "], llm=llm)\n",
    "\n",
    "twitter_thread_planner = Agent(config=agents_config['twitter_thread_planner'], tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool()\n",
    "], llm=llm)\n",
    "\n",
    "analyze_draft = Task(\n",
    "  config=tasks_config['analyze_draft'],\n",
    "  agent=draft_analyzer\n",
    ")\n",
    "\n",
    "create_twitter_thread_plan = Task(\n",
    "  config=tasks_config['create_twitter_thread_plan'],\n",
    "  agent=twitter_thread_planner,\n",
    "  output_pydantic=Thread\n",
    ")\n",
    "\n",
    "twitter_planning_crew = Crew(\n",
    "    agents=[draft_analyzer, twitter_thread_planner],\n",
    "    tasks=[analyze_draft, create_twitter_thread_plan],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agents, their tasks and crew for linkedin\n",
    "\n",
    "linkedin_post_planner = Agent(config=agents_config['linkedin_post_planner'], tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool()\n",
    "    ], llm=llm)\n",
    "\n",
    "create_linkedin_post_plan = Task(\n",
    "  config=tasks_config['create_linkedin_post_plan'],\n",
    "  agent=linkedin_post_planner,\n",
    "  output_pydantic=LinkedInPost\n",
    ")\n",
    "\n",
    "linkedin_planning_crew = Crew(\n",
    "    agents=[draft_analyzer, linkedin_post_planner],\n",
    "    tasks=[analyze_draft, create_linkedin_post_plan],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv(\"FIRECRAWL_API_KEY\")\n",
    "print(key)\n",
    "\n",
    "import firecrawl\n",
    "print(firecrawl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define state for the content planning flow\n",
    "\n",
    "class ContentPlanningState(BaseModel):\n",
    "    \"\"\"\n",
    "    State for the content planning flow\n",
    "    \"\"\"\n",
    "    blog_post_url: str = blog_post_url\n",
    "    draft_path: Path = \"assets/ \"\n",
    "    post_type: str = \"twitter\"\n",
    "    path_to_example_threads: str = \"assets/example_threads.txt\"\n",
    "    path_to_example_linkedin: str = \"assets/example_linkedin.txt\"\n",
    "\n",
    "class CreateContentPlanningFlow(Flow[ContentPlanningState]):\n",
    "    # No need for AI Agents on this step, so we just use regular Python code\n",
    "    @start()\n",
    "    def scrape_blog_post(self):\n",
    "        print(f\"# fetching draft from: {self.state.blog_post_url}\")\n",
    "        app = FirecrawlApp(api_key=os.getenv(\"FIRECRAWL_API_KEY\"))\n",
    "        scrape_result = app.scrape_url(url=self.state.blog_post_url, formats= [ 'markdown','html' ])\n",
    "        try:\n",
    "          print(scrape_result)\n",
    "          title = scrape_result.metadata.get('title', 'No title')\n",
    "          print(f\"# Title: {title}\")\n",
    "        except Exception as e:\n",
    "          title = str(uuid.uuid4())\n",
    "        self.state.draft_path = f'assets/{title}.md'\n",
    "        with open(self.state.draft_path, 'w') as f:\n",
    "          f.write(scrape_result.markdown)\n",
    "        return self.state\n",
    "\n",
    "    @router(scrape_blog_post)\n",
    "    def select_platform(self):\n",
    "        if self.state.post_type == \"twitter\":\n",
    "          return \"twitter\"\n",
    "        elif self.state.post_type == \"linkedin\":\n",
    "          return \"linkedin\"\n",
    "\n",
    "    @listen(\"twitter\")\n",
    "    def twitter_draft(self):\n",
    "        print(f\"# Planning content for: {self.state.draft_path}\")\n",
    "        \n",
    "        result = twitter_planning_crew.kickoff(inputs={'draft_path': self.state.draft_path, 'path_to_example_threads': self.state.path_to_example_threads})\n",
    "        \n",
    "        print(f\"# Planned content for {self.state.draft_path}:\")\n",
    "        \n",
    "        for i, tweet in enumerate(result.pydantic.tweets):\n",
    "            \n",
    "            print(f\"Tweet {i+1}:\")\n",
    "            print(f\"{tweet.content}\")\n",
    "            print(f\"Media URLs: {tweet.media_urls}\")\n",
    "\n",
    "            print(\"-\"*100)\n",
    "        return result\n",
    "    \n",
    "    @listen(\"linkedin\")\n",
    "    def linkedin_draft(self):\n",
    "        print(f\"# Planning content for: {self.state.draft_path}\")\n",
    "        result = linkedin_planning_crew.kickoff(inputs={'draft_path': self.state.draft_path, 'path_to_example_linkedin': self.state.path_to_example_linkedin})\n",
    "        print(f\"# Planned content for {self.state.draft_path}:\")\n",
    "        print(f\"{result.pydantic.content}\")\n",
    "        return result\n",
    "\n",
    "    @listen(or_(twitter_draft, linkedin_draft))\n",
    "    def save_plan(self, plan):\n",
    "        with open(f'output/{self.state.draft_path.split(\"/\")[-1]}_{self.state.post_type}.json', 'w') as f:\n",
    "            json.dump(plan.pydantic.model_dump(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the flow\n",
    "flow = CreateContentPlanningFlow()\n",
    "flow.state.post_type = \"twitter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.state.post_type = \"linkedin\"\n",
    "flow.kickoff()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddods-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

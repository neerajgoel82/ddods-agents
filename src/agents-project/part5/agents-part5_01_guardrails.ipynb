{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, LLM, Task, Crew, Process\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Option D: Azure OpenAI\n",
    "openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "openai_model_name = os.getenv(\"AZURE_OPENAI_MODEL_NAME\")\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"azure/gpt-4o-mini\",\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_endpoint,\n",
    "    api_version=openai_api_version,\n",
    "    azure=True\n",
    ")\n",
    "\n",
    "print(\"ðŸš€ Environment configured!\")\n",
    "print(f\"LLM Model: {llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardrails Demo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_summary_length(task_output):\n",
    "    try:\n",
    "        print(\"Validating summary length\")\n",
    "        task_str_output = str(task_output)\n",
    "        total_words = len(task_str_output.split())\n",
    "\n",
    "        print(f\"Word count: {total_words}\")\n",
    "\n",
    "        if total_words > 150:\n",
    "            print(\"Summary exceeds 150 words\")\n",
    "            return (False, f\"Summary exceeds 150 words. Word count: {total_words}\")\n",
    "\n",
    "        if total_words == 0:\n",
    "            print(\"Summary is empty\")\n",
    "            return (False, \"Generated summary is empty.\")\n",
    "\n",
    "        print(\"Summary is valid\")\n",
    "        return (True, task_output)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Validation system error\")\n",
    "        return (False, f\"Validation system error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task, Agent\n",
    "\n",
    "summary_agent = Agent(\n",
    "    role=\"Summary Agent\",\n",
    "    goal=\"Summarize the research paper 'Convolutional Neural Networks' in 150 words.\",\n",
    "    backstory=\"You are a specialized agent that summarizes research papers.\",\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "summary_task = Task(\n",
    "    description=\"Summarize a research paper in 150 words.\",\n",
    "    expected_output=\"A concise research summary 150 words.\",\n",
    "    agent=summary_agent,\n",
    "    guardrail=validate_summary_length,\n",
    "    \n",
    "    max_retries=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew\n",
    "\n",
    "summary_crew = Crew(\n",
    "    agents=[summary_agent],\n",
    "    tasks=[summary_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = summary_crew.kickoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask the agent to write a 200 word summary instead and notice the guardrail output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task, Agent\n",
    "\n",
    "summary_agent = Agent(\n",
    "    role=\"Summary Agent\",\n",
    "    goal=\"Summarize the research paper 'Convolutional Neural Networks' in 200 words.\",\n",
    "    backstory=\"You are a specialized agent that summarizes research papers.\",\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "summary_task = Task(\n",
    "    description=\"Summarize a research paper in 200 words.\",\n",
    "    expected_output=\"A concise research summary 200 words.\",\n",
    "    agent=summary_agent,\n",
    "    guardrail=validate_summary_length,\n",
    "    max_retries=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew\n",
    "\n",
    "summary_crew = Crew(\n",
    "    agents=[summary_agent],\n",
    "    tasks=[summary_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = summary_crew.kickoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardrails demo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ResearchReport(BaseModel):\n",
    "    \"\"\"Represents a structured research report\"\"\"\n",
    "    title: str\n",
    "    summary: str\n",
    "    key_findings: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Tuple, Any\n",
    "\n",
    "def validate_json_report(result: str) -> Tuple[bool, Any]:\n",
    "    \"\"\"Ensures AI-generated output is valid JSON with required fields.\"\"\"\n",
    "    try:\n",
    "        # Parse JSON output\n",
    "        data = json.loads(result.pydantic.model_dump_json())\n",
    "\n",
    "        # Check required fields\n",
    "        if \"title\" not in data or \"summary\" not in data or \"key_findings\" not in data:\n",
    "            return (False, \"Missing required fields: title, summary, or key_findings.\")\n",
    "\n",
    "        return (True, result)  # JSON is valid\n",
    "    except json.JSONDecodeError:\n",
    "        return (False, \"Invalid JSON format. Please ensure correct syntax.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent\n",
    "\n",
    "# Create the AI Agent\n",
    "research_report_agent = Agent(\n",
    "    role=\"Research Analyst\",\n",
    "    goal=\"Generate structured JSON reports for research papers\",\n",
    "    backstory=\"You are an expert in technical writing and structured reporting.\",\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task\n",
    "\n",
    "research_report_task = Task(\n",
    "    description=\"Generate a structured research report in valid JSON format.\",\n",
    "    expected_output=\"A valid JSON object containing 'title', 'summary', and 'key_findings'.\",\n",
    "    agent=research_report_agent,\n",
    "    output_pydantic=ResearchReport,  # Ensures structured output\n",
    "    guardrail=validate_json_report,  # Validate output before passing to next step\n",
    "    max_retries=3  # Allow up to 3 retries if validation fails\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew\n",
    "\n",
    "research_crew = Crew(\n",
    "    agents=[research_report_agent],\n",
    "    tasks=[research_report_task],\n",
    "    verbose=True  # Display execution details\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = research_crew.kickoff()\n",
    "\n",
    "# Display the validated JSON output\n",
    "print(\"Final Research Report:\", result.pydantic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddods-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
